{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a)a/atos\n"
     ]
    }
   ],
   "source": [
    "#make the CSV for the lemmas DF \n",
    "import pandas as pd \n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "bases_src = 'Raw_XML/hib_lemmas.xml'\n",
    "\n",
    "tree = ET.parse(bases_src)\n",
    "root = tree.getroot()\n",
    "\n",
    "#make the stuff that will form the headers \n",
    "id = []\n",
    "text = []\n",
    "bare_text = []\n",
    "sequence_num = []\n",
    "lang_id = []\n",
    "definition = []\n",
    "print(root[0][1][0][1].text)\n",
    "#only add to CSV if latin -- no grk\n",
    "for row in root[0][1]:\n",
    "    if(row[4].text == \"3\"):\n",
    "        id.append(row[0].text)\n",
    "        text.append(row[1].text)\n",
    "        bare_text.append(row[2].text)\n",
    "        sequence_num.append(row[3].text)\n",
    "        lang_id.append(row[4].text)\n",
    "        definition.append(row[5].text)\n",
    " \n",
    "\n",
    "\n",
    "dict = {\"id\": id, \"text\":text,  \"bare_text\": bare_text, \"seqence_num\": sequence_num, \"lang_id\": lang_id, \"definition\": definition}\n",
    "dict2 = {\"id\": id, \"bare_text\": bare_text, \"definition\": definition}\n",
    "df = pd.DataFrame(dict)\n",
    "df2 = pd.DataFrame(dict2)\n",
    "df2.to_csv(\"Dictionary_Dataframes/lemmas_abr.csv\", sep = \"{\")\n",
    "df.to_csv(\"Dictionary_Dataframes/lemmas.csv\", sep = \"{\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "row[0] = id\n",
    "row[1] = text\n",
    "row[2] = bare-text\n",
    "row[3] = seq # \n",
    "row[4] = lang id -- 2 is grk; 3 is ltn\n",
    "row[5] = definition\n",
    "\n",
    "Delimiter cant be: ,;:\\/|?}[]() because of existance in files\n",
    "it CAN be { so that is what current delim is in CSV files \n",
    "\n",
    "instances OF lemma_lang_id = 3 matches number of rows in CSV!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          id    bare_text                                         definition\n",
      "0      36489            A                                                NaN\n",
      "1      36490            a                            from, away from, out of\n",
      "2      36491      abactus                            driven away, driven off\n",
      "3      36492       abacus   a table of precious material for the display ...\n",
      "4      36493  abalienatio              a transfer of property, sale, cession\n",
      "...      ...          ...                                                ...\n",
      "17568  54057     Zephyrus         a gentle west wind, western breeze, zephyr\n",
      "17569  54058    zmaragdus                                                NaN\n",
      "17570  54059     zodiacus                                         the zodiac\n",
      "17571  54060         zona                       a woman's girdle, belt, zone\n",
      "17572  54061     zonarius                             of a belt, of a girdle\n",
      "\n",
      "[17573 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "#now check importing db from csv\n",
    "import pandas as pd \n",
    "df = pd.read_csv(\"lemmas_abr.csv\", sep = \"{\")\n",
    "del df['Unnamed: 0']\n",
    "#df usable from this point forward!\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "519\n"
     ]
    }
   ],
   "source": [
    "#now time for parses \n",
    "import pandas as pd \n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "bases_src = 'Raw_XML/hib_parses.xml'\n",
    "\n",
    "tree = ET.parse(bases_src)\n",
    "root = tree.getroot()\n",
    "\n",
    "#make the stuff that will form the headers \n",
    "id = []\n",
    "word_id = []\n",
    "morph_code = []\n",
    "exp_text = []\n",
    "text = []\n",
    "bare_text = []\n",
    "dialects = []\n",
    "misc_features = []\n",
    "print(root[0][1][0][1].text)\n",
    "#only add to CSV if latin -- no grk\n",
    "for row in root[0][1]:\n",
    "    word_id.append(row[0].text)\n",
    "    id.append(row[1].text)\n",
    "    morph_code.append(row[2].text)\n",
    "    exp_text.append(row[3].text)\n",
    "    text.append(row[4].text)\n",
    "    bare_text.append(row[5].text)\n",
    "    dialects.append(row[6].text)\n",
    "    misc_features.append(row[7].text)\n",
    "\n",
    "dict = {\n",
    "    \"id\": id, \n",
    "    \"word_id\": word_id, \n",
    "    \"morph_code\": morph_code, \n",
    "    \"exp_text\": exp_text, \n",
    "    \"text\": text,\n",
    "    \"bare_text\": bare_text,\n",
    "    \"dialects\": dialects,\n",
    "    \"misc_features\": misc_features}\n",
    "dict_abr = {\n",
    "    \"id\": id, \n",
    "    \"word_id\": word_id, \n",
    "    \"morph_code\": morph_code, \n",
    "    \"bare_text\": bare_text}\n",
    "df = pd.DataFrame(dict)\n",
    "df_abr = pd.DataFrame(dict_abr)\n",
    "\n",
    "df.to_csv(\"Dictionary_Dataframes/parses.csv\", sep = \"{\")\n",
    "df_abr.to_csv(\"Dictionary_Dataframes/parses_abr.csv\", sep = \"{\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "row[0] = word id\n",
    "row[1] = id <-- HOW WE MATCH TO OTHER DF \n",
    "row[2] = morphological code\n",
    "row[3] = expanded form\n",
    "row[4] = form\n",
    "row[5] = bare_form\n",
    "row[6] = dialects\n",
    "row[7] = misc features\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
